{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "21. What is a loss function and what is its purpose in machine learning?"
      ],
      "metadata": {
        "id": "Y2mHeIdZffYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loss function is a mathematical function that quantifies the discrepancy between the predicted values and the actual values in machine learning. Its purpose is to measure the model's performance and helps in optimization process during training. By evaluating the loss function, the model can adjust its parameters to minimize the error and improve its predictions."
      ],
      "metadata": {
        "id": "51Gq6VVnffSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the difference between a convex and non-convex loss function?"
      ],
      "metadata": {
        "id": "aq4GbA3KffMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convex loss function has a single global minimum, meaning it has a bowl-like shape and is relatively easy to optimize. Gradient-based optimization methods can efficiently find the minimum point, leading to convergence to the optimal solution.\n",
        "Whereas non-convex loss function has multiple local minima, making it more challenging to optimize. It may have flat regions or multiple peaks, which can lead to optimization difficulties. Finding the global minimum is more complex and may require more sophisticated optimization techniques."
      ],
      "metadata": {
        "id": "wCrGy2Z9ffG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is mean squared error (MSE) and how is it calculated?"
      ],
      "metadata": {
        "id": "M4QyRgNIffA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a popular loss function used to measure the average squared difference between predicted and actual values. It is calculated by taking the average of the squared differences between each predicted value and its corresponding actual value."
      ],
      "metadata": {
        "id": "FMmA6dGrfe7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. What is mean absolute error (MAE) and how is it calculated?"
      ],
      "metadata": {
        "id": "LeB3OW_1fe2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a loss function that measures the average absolute difference between predicted and actual values. It is calculated by taking the average of the absolute differences between each predicted value and its corresponding actual value."
      ],
      "metadata": {
        "id": "TP6JmYBUfeww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. What is log loss (cross-entropy loss) and how is it calculated?"
      ],
      "metadata": {
        "id": "7GDtWlD0feqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is commonly used for classification problems in machine learning. It measures the performance of a classification model that outputs probabilities. Log loss quantifies the difference between the predicted probabilities and the true labels. It is calculated by taking the negative logarithm of the predicted probability for the true class."
      ],
      "metadata": {
        "id": "KVcogyOafelW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. How do you choose the appropriate loss function for a given problem?"
      ],
      "metadata": {
        "id": "rqJBKugNfefu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the appropriate loss function depends on the specific problem and the nature of the data. If it is a regression or classification problem, the considerations based on desired properties of the loss function such as convexity, robustness to outliers etc., and the underlying assumptions of the problem."
      ],
      "metadata": {
        "id": "f1_hztbNfeab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Explain the concept of regularization in the context of loss functions."
      ],
      "metadata": {
        "id": "Rm-dWHObfeTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a technique used to prevent overfitting and improve the generalization of a model. It is typically achieved by adding a penalty term to the loss function. The penalty discourages the model from fitting the training data too closely by introducing a bias towards simpler models. Regularization helps to control the complexity of the model and prevent over-reliance on specific features."
      ],
      "metadata": {
        "id": "Dw3eVV_qfdSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. What is Huber loss and how does it handle outliers?\n"
      ],
      "metadata": {
        "id": "nZVyOhmofdP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Huber loss is a loss function that combines the best properties of squared loss (MSE) and absolute loss (MAE). It is less sensitive to outliers than squared loss and provides better gradient properties near the minimum. Huber loss switches between the squared loss and absolute loss based on a predefined threshold. It is robust to outliers, providing a compromise between the two other loss functions."
      ],
      "metadata": {
        "id": "00XwErW6fdKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What is quantile loss and when is it used?\n"
      ],
      "metadata": {
        "id": "psPaxTv2fdH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantile loss is a loss function used for quantile regression. It measures the accuracy of predicting a specific quantile of the target variable. Unlike mean-based loss functions (MSE, MAE), quantile loss gives higher penalties to predictions that fall below or above the target quantile. It is useful when the goal is to estimate specific quantiles of the target distribution."
      ],
      "metadata": {
        "id": "KRkcHA-YfdFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. What is the difference between squared loss and absolute loss?"
      ],
      "metadata": {
        "id": "aPeGiNATfdA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between squared loss and absolute loss lies in their sensitivity to outliers and the type of error they emphasize. Squared loss (MSE) penalizes larger errors more heavily due to the squaring operation, making it more sensitive to outliers. Absolute loss (MAE) treats all errors equally, giving the same weight to each prediction error regardless of its magnitude. Squared loss emphasizes larger errors and is differentiable, while absolute loss is more robust to outliers and less sensitive to extreme values."
      ],
      "metadata": {
        "id": "LmgIQaGJfc-g"
      }
    }
  ]
}